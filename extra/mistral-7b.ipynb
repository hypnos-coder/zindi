{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T08:21:04.224976Z",
     "iopub.status.busy": "2024-10-27T08:21:04.224446Z",
     "iopub.status.idle": "2024-10-27T08:21:22.005919Z",
     "shell.execute_reply": "2024-10-27T08:21:22.004454Z",
     "shell.execute_reply.started": "2024-10-27T08:21:04.224919Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Downloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jiter, openai\n",
      "Successfully installed jiter-0.6.1 openai-1.52.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T08:21:22.009077Z",
     "iopub.status.busy": "2024-10-27T08:21:22.008627Z",
     "iopub.status.idle": "2024-10-27T08:21:22.017092Z",
     "shell.execute_reply": "2024-10-27T08:21:22.015888Z",
     "shell.execute_reply.started": "2024-10-27T08:21:22.009032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY = \"\"\n",
    "%env OPENAI_BASE_URL =\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T08:21:22.018856Z",
     "iopub.status.busy": "2024-10-27T08:21:22.018399Z",
     "iopub.status.idle": "2024-10-27T08:21:23.482187Z",
     "shell.execute_reply": "2024-10-27T08:21:23.480829Z",
     "shell.execute_reply.started": "2024-10-27T08:21:22.018796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "# ?\\df = pd.read_json(\"hf://datasets/AGBonnet/augmented-clinical-notes/augmented_notes_30K.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T13:52:31.012830Z",
     "iopub.status.busy": "2024-10-27T13:52:31.012322Z",
     "iopub.status.idle": "2024-10-27T13:52:31.177604Z",
     "shell.execute_reply": "2024-10-27T13:52:31.175969Z",
     "shell.execute_reply.started": "2024-10-27T13:52:31.012784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/6669ynhgoug/output_16000.csv', on_bad_lines='skip')\n",
    "data = df.iloc[:, 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T13:52:31.284316Z",
     "iopub.status.busy": "2024-10-27T13:52:31.283763Z",
     "iopub.status.idle": "2024-10-27T13:52:31.438681Z",
     "shell.execute_reply": "2024-10-27T13:52:31.437286Z",
     "shell.execute_reply.started": "2024-10-27T13:52:31.284268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/kaggle/input/6669ynhgoug/output_17000.csv', on_bad_lines='skip')\n",
    "data1 = df1.iloc[:, 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T13:52:31.977809Z",
     "iopub.status.busy": "2024-10-27T13:52:31.977266Z",
     "iopub.status.idle": "2024-10-27T13:52:31.984339Z",
     "shell.execute_reply": "2024-10-27T13:52:31.982884Z",
     "shell.execute_reply.started": "2024-10-27T13:52:31.977759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_list = data.tolist()\n",
    "data_list1 = data1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T13:52:32.370453Z",
     "iopub.status.busy": "2024-10-27T13:52:32.369900Z",
     "iopub.status.idle": "2024-10-27T13:52:32.377667Z",
     "shell.execute_reply": "2024-10-27T13:52:32.376181Z",
     "shell.execute_reply.started": "2024-10-27T13:52:32.370404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_list2000 = data_list+data_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T13:52:32.856793Z",
     "iopub.status.busy": "2024-10-27T13:52:32.856132Z",
     "iopub.status.idle": "2024-10-27T13:52:32.865075Z",
     "shell.execute_reply": "2024-10-27T13:52:32.863173Z",
     "shell.execute_reply.started": "2024-10-27T13:52:32.856692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "used_date = data_list2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T13:53:13.518492Z",
     "iopub.status.busy": "2024-10-27T13:53:13.517987Z",
     "iopub.status.idle": "2024-10-27T15:40:21.842281Z",
     "shell.execute_reply": "2024-10-27T15:40:21.840805Z",
     "shell.execute_reply.started": "2024-10-27T13:53:13.518448Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk: 100%|██████████| 1999/1999 [1:47:08<00:00,  3.22s/it]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "# 设置OpenAI API密钥\n",
    "results = []\n",
    "for message in tqdm(used_date, desc=f\"Processing chunk\"):\n",
    "    prompt = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"Please synthesize the following patient's medical information into a single, coherent paragraph suitable for inclusion in a medical record. Begin the paragraph with a varied and engaging opening that sets the context for the patient's story. The paragraph should be professional, concise, and accessible to a layperson, avoiding medical jargon where possible.\n",
    "\n",
    "[Medical Information]\n",
    "{message}\n",
    "\n",
    "Ensure the paragraph includes the patient's chief complaints, medical history, diagnostic findings, diagnosis, treatment details, postoperative course, and follow-up information. The opening should be diverse and not limited to a specific format, allowing the model to generate a variety of introductions that still lead into the detailed medical narrative.\n",
    "\n",
    "The only output is in text.\"\"\"\n",
    "    }\n",
    "    messages = [prompt]\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        response_content = response.choices[0].message.content.strip()\n",
    "        results.append(response_content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing item: {e}\")\n",
    "\n",
    "        # 每处理1000个标注后保\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T14:48:17.733420Z",
     "iopub.status.busy": "2024-10-24T14:48:17.732978Z",
     "iopub.status.idle": "2024-10-24T14:48:17.741585Z",
     "shell.execute_reply": "2024-10-24T14:48:17.740380Z",
     "shell.execute_reply.started": "2024-10-24T14:48:17.733382Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(used_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T05:47:15.717919Z",
     "iopub.status.busy": "2024-10-27T05:47:15.717517Z",
     "iopub.status.idle": "2024-10-27T05:47:15.724329Z",
     "shell.execute_reply": "2024-10-27T05:47:15.723285Z",
     "shell.execute_reply.started": "2024-10-27T05:47:15.717879Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Patient X presents with a sudden onset of speech impairment, coordination defects, difficulty manipulating a leash, clumsiness with the right hand, forgetfulness, disorganized thoughts, and slurred speech. The patient's medical history reveals a previous injury of migraines with occasional visual auras and scoliosis. Diagnostic findings include an unremarkable CT scan, magnetic resonance imaging indicating an acute left parietal operculum ischemic infarct with involvement of the mid left temporal lobe, recent embolic infarcts in the centrum semiovale bilaterally, less than 30% stenosis of bilateral carotid arteries based on carotid duplex imaging, normal transcranial doppler results, focal aneurysmal dilatation of the right subclavian artery and left brachiocephalic vein in the supraclavicular fossa revealed by magnetic resonance angiography, and a chest x-ray showing no acute cardiopulmonary disease. Serologic studies indicate an elevated total cholesterol level of 218mg/dL. The diagnosis is ASA-Right Bubbles, an embolic disease located in the brain. Treatment includes medical management, specifically aspirin 325mg daily and discontinuation of hormone replacement therapy. The patient has had a five-year follow-up without any new cerebral ischemic events and is currently active and functionally independent, as per the postoperative course.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T15:40:27.331304Z",
     "iopub.status.busy": "2024-10-27T15:40:27.329874Z",
     "iopub.status.idle": "2024-10-27T15:40:27.489199Z",
     "shell.execute_reply": "2024-10-27T15:40:27.487838Z",
     "shell.execute_reply.started": "2024-10-27T15:40:27.331241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 保存结果到CSV\n",
    "def save_results_to_csv(results, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['text']  # 只包含一个字段 'text'\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for result in results:\n",
    "            writer.writerow({'text': result})\n",
    "\n",
    "# 处理完成后再次保存所有结果\n",
    "csv_filename = \"output_new_16-17000.csv\"\n",
    "save_results_to_csv(results, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T14:48:28.074010Z",
     "iopub.status.busy": "2024-10-24T14:48:28.073635Z",
     "iopub.status.idle": "2024-10-24T15:34:06.405506Z",
     "shell.execute_reply": "2024-10-24T15:34:06.403734Z",
     "shell.execute_reply.started": "2024-10-24T14:48:28.073973Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:   1%|          | 4/500 [00:28<46:29,  5.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:   2%|▏         | 9/500 [01:05<58:45,  7.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:   4%|▎         | 18/500 [02:01<1:03:50,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Extra data: line 58 column 1 (char 2490)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:   6%|▌         | 28/500 [02:55<40:23,  5.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Extra data: line 1 column 1168 (char 1167)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:   9%|▉         | 47/500 [04:41<43:24,  5.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  11%|█         | 56/500 [05:21<27:43,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  12%|█▏        | 60/500 [05:37<24:41,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  15%|█▍        | 73/500 [06:44<40:11,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  18%|█▊        | 91/500 [08:36<44:55,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  19%|█▉        | 97/500 [09:03<33:36,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting ':' delimiter: line 11 column 5 (char 373)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  22%|██▏       | 108/500 [09:55<25:13,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  22%|██▏       | 110/500 [10:01<21:04,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  24%|██▎       | 118/500 [10:35<21:05,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  24%|██▍       | 122/500 [10:52<23:56,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  32%|███▏      | 158/500 [14:03<36:25,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  33%|███▎      | 165/500 [14:38<21:21,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  33%|███▎      | 167/500 [14:46<22:24,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  36%|███▌      | 181/500 [16:02<29:29,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  38%|███▊      | 188/500 [16:33<25:08,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  40%|████      | 201/500 [17:49<30:06,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Extra data: line 53 column 1 (char 1635)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  41%|████      | 203/500 [18:04<34:11,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Extra data: line 101 column 1 (char 4158)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  41%|████      | 204/500 [18:08<29:00,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Extra data: line 23 column 1 (char 721)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  43%|████▎     | 213/500 [18:58<26:45,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  47%|████▋     | 236/500 [21:06<22:43,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  47%|████▋     | 237/500 [21:14<26:41,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  48%|████▊     | 240/500 [21:22<16:14,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  50%|████▉     | 248/500 [22:02<20:27,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  50%|████▉     | 249/500 [22:07<20:42,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Extra data: line 46 column 1 (char 1430)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  50%|█████     | 251/500 [22:10<13:09,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  56%|█████▌    | 278/500 [24:50<18:14,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  56%|█████▌    | 280/500 [25:03<21:11,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  57%|█████▋    | 284/500 [25:25<21:54,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  58%|█████▊    | 292/500 [26:15<21:04,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting ',' delimiter: line 45 column 2 (char 1905)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  61%|██████    | 305/500 [27:31<20:57,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  67%|██████▋   | 334/500 [30:34<12:05,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  68%|██████▊   | 338/500 [30:48<08:44,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  69%|██████▉   | 346/500 [31:31<14:39,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  72%|███████▏  | 362/500 [32:59<11:49,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  75%|███████▍  | 374/500 [34:07<14:22,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  77%|███████▋  | 386/500 [35:17<08:02,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  78%|███████▊  | 391/500 [35:48<11:58,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Extra data: line 46 column 1 (char 2368)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  85%|████████▌ | 425/500 [38:45<04:54,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  89%|████████▉ | 445/500 [40:22<04:31,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting ',' delimiter: line 57 column 2 (char 1927)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  89%|████████▉ | 446/500 [40:31<05:36,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  91%|█████████ | 456/500 [41:33<05:02,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  91%|█████████▏| 457/500 [41:41<05:13,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  95%|█████████▌| 476/500 [43:37<02:23,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting ':' delimiter: line 12 column 1 (char 369)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  96%|█████████▌| 478/500 [43:47<01:57,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  97%|█████████▋| 483/500 [44:11<01:25,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  97%|█████████▋| 486/500 [44:26<01:05,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk:  98%|█████████▊| 489/500 [44:41<00:56,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting ':' delimiter: line 10 column 1 (char 249)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk: 100%|██████████| 500/500 [45:38<00:00,  5.48s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "# 设置OpenAI API密钥\n",
    "results = []\n",
    "for message in tqdm(used_date, desc=f\"Processing chunk\"):\n",
    "    prompt = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"As a professional clinical notes organizer, my task is to take a set of clinical notes and structure them into a JSON format. This format will help in standardizing the patient data for better analysis and record-keeping. Below, I will explain each field in the JSON structure and provide an example based on a hypothetical clinical note.\n",
    "\n",
    "    JSON Field Explanation:\n",
    "\n",
    "    PatientInformation: This section captures the patient's presenting complaints and historical medical information.\n",
    "    ChiefComplaints: A list of the main issues the patient is experiencing, as reported by the patient.\n",
    "    MedicalHistory: Includes any past injuries or significant health issues that are relevant to the current condition.\n",
    "    DiagnosticFindings: A list of diagnostic tests conducted and their findings. Each item includes the type of Test conducted and the Finding from that test\n",
    "\n",
    "    Diagnosis: This section includes the diagnosed disease.\n",
    "    Disease: Details the name, type, and location of the diagnosed disease.\n",
    "\n",
    "    TreatmentAndOutcome: This section outlines the treatment provided and the subsequent outcome.\n",
    "    Treatment: Describes the type of treatment and any specific details about the procedure.\n",
    "    Type: The general category of treatment.\n",
    "    Details: Specifics about what the treatment entailed.\n",
    "    Postoperative Course: Information about the recovery process after surgery.\n",
    "    Recovery: General description of the recovery process.\n",
    "    FollowUp: Information about any follow-up care or observations.\n",
    "    FunctionalStatus: Any observations about the patient's functionality or quality of life post-treatment.\n",
    "\n",
    "    Example Output:\n",
    "    {{\n",
    "    \"PatientInformation\": {{\n",
    "        \"ChiefComplaints\": [\n",
    "        \"Complaints of pain and swelling in the right back for several weeks\",\n",
    "        \"No significant health problems except a thoracic trauma one year prior\"\n",
    "        ],\n",
    "        \"MedicalHistory\": {{\n",
    "        \"PreviousInjury\": \"Thoracic trauma with a simple fracture of the 9th right rib\"\n",
    "        }},\n",
    "        \"DiagnosticFindings\": [\n",
    "        {{\n",
    "            \"Test\": \"X-ray\",\n",
    "            \"Finding\": \"A shadow in the lower part of the right hemithorax\"\n",
    "        }},\n",
    "        {{\n",
    "            \"Test\": \"CT-scan\",\n",
    "            \"Finding\": \"A tumor with heterogeneous density and destruction of the 9th rib\"\n",
    "        }}\n",
    "        ]\n",
    "    }},\n",
    "    \"Diagnosis\": {{\n",
    "        \"Disease\": {{\n",
    "        \"Name\": \"Sclerosing xanthofibroma\",\n",
    "        \"Type\": \"Benign tumor\",\n",
    "        \"Location\": \"Thoracic wall\"\n",
    "        }}\n",
    "    }},\n",
    "    \"TreatmentAndOutcome\": {{\n",
    "        \"Treatment\": {{\n",
    "        \"Type\": \"Surgical resection and plastic repair\",\n",
    "        \"Details\": \"Involving three ribs and reconstruction with polypropylene mesh\"\n",
    "        }},\n",
    "        \"Postoperative Course\": {{\n",
    "        \"Recovery\": \"Uneventful\",\n",
    "        \"DischargeStatus\": \"Good condition\"\n",
    "        }},\n",
    "        \"FollowUp\": {{\n",
    "        \"Duration\": \"Two years\",\n",
    "        \"FunctionalStatus\": \"Patient returned to work one month after surgery\"\n",
    "        }}\n",
    "    }}\n",
    "    }}\n",
    "    Medical case data:\n",
    "    {message}\n",
    "    The only output is Json file\"\"\"\n",
    "        }\n",
    "    messages = [prompt]\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        response_content = response.choices[0].message.content.strip()\n",
    "\n",
    "        try:\n",
    "            parsed_json = json.loads(response_content)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON: {e}\")\n",
    "            parsed_json = response_content\n",
    "        results.append(parsed_json) \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing item: {e}\")\n",
    "\n",
    "        # 每处理1000个标注后保\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T09:23:29.005803Z",
     "iopub.status.busy": "2024-10-24T09:23:29.004824Z",
     "iopub.status.idle": "2024-10-24T09:23:29.014152Z",
     "shell.execute_reply": "2024-10-24T09:23:29.012932Z",
     "shell.execute_reply.started": "2024-10-24T09:23:29.005749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T15:40:46.844909Z",
     "iopub.status.busy": "2024-10-24T15:40:46.844061Z",
     "iopub.status.idle": "2024-10-24T15:40:46.946117Z",
     "shell.execute_reply": "2024-10-24T15:40:46.944773Z",
     "shell.execute_reply.started": "2024-10-24T15:40:46.844839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 保存结果到CSV\n",
    "def save_results_to_csv(data, results, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['input', 'output']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for data_item, result in zip(data, results):\n",
    "            writer.writerow({'input': data_item, 'output': result})\n",
    "\n",
    "\n",
    "# 处理完成后再次保存所有结果\n",
    "csv_filename = \"output_1000.csv\"\n",
    "save_results_to_csv(used_date, results, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T04:07:22.148475Z",
     "iopub.status.busy": "2024-10-21T04:07:22.147982Z",
     "iopub.status.idle": "2024-10-21T04:07:22.157065Z",
     "shell.execute_reply": "2024-10-21T04:07:22.155717Z",
     "shell.execute_reply.started": "2024-10-21T04:07:22.148428Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A a sixteen year-old girl, presented to our Outpatient department with the complaints of discomfort in the neck and lower back as well as restriction of body movements. She was not able to maintain an erect posture and would tend to fall on either side while standing up from a sitting position. She would keep her head turned to the right and upwards due to the sustained contraction of the neck muscles. There was a sideways bending of the back in the lumbar region. To counter the abnormal positioning of the back and neck, she would keep her limbs in a specific position to allow her body weight to be supported. Due to the restrictions with the body movements at the neck and in the lumbar region, she would require assistance in standing and walking. She would require her parents to help her with daily chores, including all activities of self-care.\\\\nShe had been experiencing these difficulties for the past four months since when she was introduced to olanzapine tablets for the control of her exacerbated mental illness. This was not her first experience with this drug over the past seven years since she had been diagnosed with bipolar affective disorder. Her first episode of the affective disorder was that of mania at the age of eleven which was managed with the use of olanzapine tablets in 2.5–10 mg doses per day at different times. The patient developed pain and discomfort in her neck within the second week of being put on tablet olanzapine at a dose of 5 mg per day. This was associated with a sustained and abnormal contraction of the neck muscles that would pull her head to the right in an upward direction. These features had persisted for the first three years of her illness with a varying intensity, distress, and dysfunction which would tend to correlate with the dose of olanzapine. Apart from a brief period of around three weeks when she was given tablet trihexyphenidyl 4 mg per day for rigidity in her upper limbs, she was not prescribed any other psychotropic medication. The rigidity showed good response to this medication which was subsequently stopped. The introduction and subsequent withdrawal of this medication did not bring about any change in the sustained abnormal contraction of her neck muscles.\\\\nImprovement and subsequent remission of the mood symptoms of the patient provided the treatment team with an opportunity to stop olanzapine. The discomfort in the neck and the abnormal movement of the neck muscles persisted over the next three months’ period when she was off olanzapine without any significant change, even with a trial of propranolol, trihexyphenidyl, and phenargan injection. Reintroduction of olanzapine (at a dose of 2.5 mg per day) after a gap of three months for the reemergence of some behavioral features led to a slight aggravation of the already existing abnormal movement and posturing of the neck.\\\\nWith improvement in the clinical picture, olanzapine was reduced and stopped. She was put on tablet sodium valproate, 1000 mg per day during this period for the stabilization of her mood when she was also given escitalopram for a period of three months for her depressive features. The patient responded well to this change in medication, but she developed amenorrhea for which no cause was established after a detailed gynecological evaluation. Keeping in mind the possibility of valproate-induced menstrual disturbance, she was shifted to tablet lithium 450 mg per day. The patient was well maintained on this medication for a period of around two years. However, she developed hypothyroidism for which eltroxin was introduced at a dose of 50 micrograms per day.\\\\nDuring this period of two years and seven months, the abnormal contraction of the neck muscles and the abnormal positioning of the head improved slightly, and with the improvement, it would cause less discomfort and interference in her activities. However, these movements failed to disappear completely. Another exacerbation of the mood symptoms in the form of mania warranted a need for the introduction of olanzapine (by a different treatment team) and the patient was reintroduced to 10 mg olanzapine on a daily basis, which led to the current presentation as described earlier.\\\\nAfter the case was seen at our institute, the psychotropic medications were stopped as her mood symptoms had remitted and she was put on tablet tetrabenazine (built up to 75 mg per day in divided doses) with which the patient had started showing some response with an improvement in abnormal movements of the muscles of the neck as well as the back. She is now able to stand with support and can do some daily chores on her own. The pain and discomfort in the back and neck have also reduced.\\\\nDuring the course of the illness, the patient has been investigated for the presence of any neurological illness as the cause of her abnormal movements. Her MRI scan of the brain, serum and urine copper levels, slit lamp microscopy for the KF ring, complete blood count, TLC, DLC, and USG of the abdomen did not reveal any abnormalities. Her thyroid function tests were deranged subsequent to the introduction of tablet lithium carbonate which was restored to normal after the introduction of tablet eltroxin.\\\\nDystonia is a syndrome of sustained muscle contractions that produce twisting and repetitive movements or abnormal postures. The descriptions of the extent and severity of muscle involvement are variable, ranging from intermittent contraction limited to a single body region, to generalized dystonia involving the limbs and axial muscles.\\\\nEver since the introduction of the term, “dystonia” by Oppenhiem in the early part of the twentieth century, it has been an area of focused attention of the neurologists. In 1973, Keegan and Rajput introduced the term, “” to describe drug-induced, sustained muscle spasm causing repetitive movements or abnormal postures. “” was a term introduced by Burke in 1982, the description of which required the presence of chronic dystonia, a history of antipsychotic drug treatment preceding or concurrent with the onset of dystonia, the exclusion of known causes of secondary dystonia by appropriate clinical and laboratory evaluation, and a negative family history of dystonia for definitive diagnosis.\\\\nThe dystonia could be classified based on the region(s) of the body involved. Involvement of isolated regions like the face, neck, and arms would be labeled as focal dystonia, whereas simultaneous involvement of two or more contiguous areas would be called segmental dystonia. When the clinical picture is that of involvement of two or more noncontiguous regions, the label used is, “multifocal” and the involvement of one leg and one other body region makes it the generalized type.\\\\nThe symptoms of tardive dystonia could begin even after a few days or weeks of exposure to the offending agent. Tardive dystonia is prevalent in 0.5–21.6% of the patients who are treated with neuroleptics.\\\\nThe syndrome of tardive dystonia has been reported with most of the typical antipsychotics.[] It has been associated with the atypical antipsychotics, namely risperidone, olanzapine, quetiapine, and aripiprazole. Reports of tardive dystonia developing with the use of atypical antipsychotics have been predominantly in the cases of nonaffective psychosis and in the adult population in the age ranges of the midthirties and forties. Our case is the first case of an affective illness in an adolescent girl developing tardive dystonia on olanzapine. The aggravation of the clinical features with the inadvertent reintroduction of the medication suggests olanzapine is the offending agent. With the growing acceptance of olanzapine as the first-line therapy for the manic phase of bipolar illness and as a mood stabilizer for the maintenance therapy, one needs to be cautious about the emergence of this troublesome adverse effect of this therapy. The patient has shown some response to the introduction of tetrabenazine.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T04:04:04.845836Z",
     "iopub.status.busy": "2024-10-21T04:04:04.845361Z",
     "iopub.status.idle": "2024-10-21T04:04:04.855443Z",
     "shell.execute_reply": "2024-10-21T04:04:04.853979Z",
     "shell.execute_reply.started": "2024-10-21T04:04:04.845792Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PatientInformation': {'ChiefComplaints': ['Complaints of discomfort in the neck and lower back with restriction of body movements',\n",
       "   'Difficulty maintaining an erect posture and tendency to fall on either side while standing up from a sitting position',\n",
       "   'Sustained contraction of neck muscles with head turned to the right and upwards'],\n",
       "  'MedicalHistory': {'PreviousInjury': 'No significant health problems except for bipolar affective disorder'},\n",
       "  'DiagnosticFindings': [{'Test': 'MRI scan of the brain',\n",
       "    'Finding': 'No abnormalities'},\n",
       "   {'Test': 'Serum and urine copper levels', 'Finding': 'Within normal range'},\n",
       "   {'Test': 'Thyroid function tests',\n",
       "    'Finding': 'Deranged after lithium carbonate, restored to normal with eltroxin'}]},\n",
       " 'Diagnosis': {'Disease': {'Name': 'Tardive dystonia',\n",
       "   'Type': 'Induced dystonia',\n",
       "   'Location': 'Neck and lower back'}},\n",
       " 'TreatmentAndOutcome': {'Treatment': {'Type': 'Tetrabenazine',\n",
       "   'Details': 'Building up to 75 mg per day in divided doses'},\n",
       "  'Postoperative Course': {'Recovery': 'Improvement in abnormal movements of neck and back',\n",
       "   'DischargeStatus': 'Stable condition'},\n",
       "  'FollowUp': {'Duration': 'Ongoing',\n",
       "   'FunctionalStatus': 'Able to stand with support and perform daily chores'}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T04:08:50.981851Z",
     "iopub.status.busy": "2024-10-21T04:08:50.981377Z",
     "iopub.status.idle": "2024-10-21T04:08:51.257761Z",
     "shell.execute_reply": "2024-10-21T04:08:51.256557Z",
     "shell.execute_reply.started": "2024-10-21T04:08:50.981807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "csv_filename = \"1000output.csv\"\n",
    "import csv\n",
    "# 使用'w'模式打开文件，如果需要在不同操作系统上保持一致的换行符，可以使用'w\\n'\n",
    "with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    # 创建一个csv的DictWriter对象，指定列名\n",
    "    fieldnames = ['input', 'output']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # 写入列名作为CSV的头部\n",
    "    writer.writeheader()\n",
    "\n",
    "    # 遍历data_list的前500个元素和results列表，将它们写入CSV文件\n",
    "    for data, result in zip(data_list[:1000], results):\n",
    "        # 将输入和输出写入CSV文件\n",
    "        writer.writerow({'input': data, 'output': result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T09:42:34.279529Z",
     "iopub.status.busy": "2024-10-20T09:42:34.278479Z",
     "iopub.status.idle": "2024-10-20T09:42:34.287919Z",
     "shell.execute_reply": "2024-10-20T09:42:34.286714Z",
     "shell.execute_reply.started": "2024-10-20T09:42:34.279472Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PatientInformation': {'ChiefComplaints': ['Patient presented with neck pain, diaphoresis, and cardiac/respiratory arrest after chiropractic neck manipulation'],\n",
       "  'MedicalHistory': {'PreviousMedicalHistory': 'No significant past medical history'},\n",
       "  'DiagnosticFindings': [{'Test': 'CT stroke protocol',\n",
       "    'Finding': 'Bilateral severe distal cervical vertebral artery dissections with acute thrombotic emboli seen in the left cervical vertebral artery'},\n",
       "   {'Test': 'Angiography',\n",
       "    'Finding': 'Severe dissection involving the distal cervical vertebral artery segments with occlusive clot in the left Posterior Inferior Cerebellar Artery (PICA)'}]},\n",
       " 'Diagnosis': {'Disease': {'Name': 'Acute basilar artery occlusion',\n",
       "   'Type': 'Vascular condition',\n",
       "   'Location': 'Basilar tip and vertebral arteries'}},\n",
       " 'TreatmentAndOutcome': {'Treatment': {'Type': 'Endovascular intervention with thrombectomy',\n",
       "   'Details': 'Distal aspiration with Penumbra 5 Max ACE catheter followed by stent retriever deployment in left distal PCA'},\n",
       "  'Postoperative Course': {'Recovery': 'No significant recanalization achieved in left PCA territory',\n",
       "   'DischargeStatus': 'Transported to intensive care unit for further monitoring'},\n",
       "  'FollowUp': {'Duration': 'Ongoing monitoring in the intensive care unit',\n",
       "   'FunctionalStatus': 'Assessment of brainstem integrity and cerebrovascular status ongoing'}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# # 读取数据\n",
    "# df = pd.read_json(\"hf://datasets/AGBonnet/augmented-clinical-notes/augmented_notes_30K.jsonl\", lines=True)\n",
    "# data_list = df['full_note']\n",
    "\n",
    "# # 设置OpenAI API密钥\n",
    "# openai.api_key = \"sk-aNkClG-Oqbtdj9CF0i7BMEWx4UJ-ud4KSMLyAO6lgZT3BlbkFJH7MdBqD3nVv60lDJk38GlWVdH0aM3OrBruDO6SydoA\"\n",
    "\n",
    "# 定义处理函数\n",
    "def process_data(data, results, chunk_size=1000):\n",
    "    for start in range(0, len(data), chunk_size):\n",
    "        chunk = data[start:start + chunk_size]\n",
    "        chunk_results = []\n",
    "        for data_item in tqdm(chunk, desc=f\"Processing chunk {start // chunk_size + 1}\"):\n",
    "            prompt = {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"...\"\"\"  # 你的prompt内容\n",
    "                Medical case data:\n",
    "                {data_item}\n",
    "                The only output is Json file\"\"\"\n",
    "            }\n",
    "            messages = [prompt]\n",
    "            try:\n",
    "                response = openai.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=messages,\n",
    "                )\n",
    "                response_content = response.choices[0].message.content.strip()\n",
    "                chunk_results.append(response_content)\n",
    "                try:\n",
    "                    parsed_json = json.loads(response_content)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing JSON: {e}\")\n",
    "                    parsed_json = response_content\n",
    "                chunk_results.append(parsed_json)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing item: {e}\")\n",
    "                chunk_results.append({\"error\": str(e)})\n",
    "        results.extend(chunk_results)\n",
    "        # 每处理1000个标注后保存结果\n",
    "        csv_filename = f\"output_{start // chunk_size * chunk_size}.csv\"\n",
    "        save_results_to_csv(chunk, chunk_results, csv_filename)\n",
    "\n",
    "# 保存结果到CSV\n",
    "def save_results_to_csv(data, results, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['input', 'output']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for data_item, result in zip(data, results):\n",
    "            writer.writerow({'input': data_item, 'output': result})\n",
    "\n",
    "# 开始处理数据\n",
    "results = []\n",
    "process_data(data_list, results)\n",
    "\n",
    "# 处理完成后再次保存所有结果\n",
    "csv_filename = \"output_all.csv\"\n",
    "save_results_to_csv(data_list, results, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import notebook_login,login\n",
    "login(token = \"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\")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BioMistral/BioMistral-7B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"BioMistral/BioMistral-7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T13:37:38.331496Z",
     "iopub.status.busy": "2024-10-19T13:37:38.330425Z",
     "iopub.status.idle": "2024-10-19T13:37:38.791339Z",
     "shell.execute_reply": "2024-10-19T13:37:38.789488Z",
     "shell.execute_reply.started": "2024-10-19T13:37:38.331425Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m eval_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mFrom the MedQuad MedicalQA Dataset: Given the following medical question and question type, provide an accurate answer:\u001b[39m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m### Question type:\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m### Answer:\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m model_input \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(eval_prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"From the MedQuad MedicalQA Dataset: Given the following medical question and question type, provide an accurate answer:\n",
    "\n",
    "### Question type:\n",
    "symptoms\n",
    "\n",
    "### Question:\n",
    "What are the symptoms of Norrie disease ?\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=300)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-18T12:19:19.672010Z",
     "iopub.status.busy": "2024-10-18T12:19:19.671002Z",
     "iopub.status.idle": "2024-10-18T12:19:19.683836Z",
     "shell.execute_reply": "2024-10-18T12:19:19.682632Z",
     "shell.execute_reply.started": "2024-10-18T12:19:19.671958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-18T12:20:51.708026Z",
     "iopub.status.busy": "2024-10-18T12:20:51.707281Z",
     "iopub.status.idle": "2024-10-18T12:20:53.756884Z",
     "shell.execute_reply": "2024-10-18T12:20:53.755464Z",
     "shell.execute_reply.started": "2024-10-18T12:20:51.707988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-18T14:24:52.846907Z",
     "iopub.status.busy": "2024-10-18T14:24:52.845849Z",
     "iopub.status.idle": "2024-10-18T14:24:53.082418Z",
     "shell.execute_reply": "2024-10-18T14:24:53.081432Z",
     "shell.execute_reply.started": "2024-10-18T14:24:52.846852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 替换为你的GitHub链接\n",
    "url = \"https://raw.githubusercontent.com/Incredible88/Clinical-note-Sum/main/output500.csv\"\n",
    "\n",
    "# 读取CSV文件\n",
    "try:\n",
    "    df = pd.read_csv(url, on_bad_lines='skip')\n",
    "    print(\"文件读取成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"读取文件时发生错误：{e}\")\n",
    "\n",
    "\n",
    "data = df.iloc[:, 1].reset_index(drop=True)  # 重置索引\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-18T13:17:30.658018Z",
     "iopub.status.busy": "2024-10-18T13:17:30.657630Z",
     "iopub.status.idle": "2024-10-18T13:17:30.666049Z",
     "shell.execute_reply": "2024-10-18T13:17:30.665149Z",
     "shell.execute_reply.started": "2024-10-18T13:17:30.657977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-18T14:19:29.105809Z",
     "iopub.status.busy": "2024-10-18T14:19:29.105427Z",
     "iopub.status.idle": "2024-10-18T14:19:45.737017Z",
     "shell.execute_reply": "2024-10-18T14:19:45.735856Z",
     "shell.execute_reply.started": "2024-10-18T14:19:29.105771Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-18T14:22:11.963750Z",
     "iopub.status.busy": "2024-10-18T14:22:11.962855Z",
     "iopub.status.idle": "2024-10-18T14:22:12.042302Z",
     "shell.execute_reply": "2024-10-18T14:22:12.041287Z",
     "shell.execute_reply.started": "2024-10-18T14:22:11.963693Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(pd.DataFrame(data, columns=['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-18T14:22:38.963831Z",
     "iopub.status.busy": "2024-10-18T14:22:38.963184Z",
     "iopub.status.idle": "2024-10-18T14:22:38.971857Z",
     "shell.execute_reply": "2024-10-18T14:22:38.970878Z",
     "shell.execute_reply.started": "2024-10-18T14:22:38.963791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-18T14:29:29.869440Z",
     "iopub.status.busy": "2024-10-18T14:29:29.868502Z",
     "iopub.status.idle": "2024-10-18T14:29:29.894056Z",
     "shell.execute_reply": "2024-10-18T14:29:29.893260Z",
     "shell.execute_reply.started": "2024-10-18T14:29:29.869393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "data_list = data.tolist()\n",
    "dataset = Dataset.from_dict({\"text\": data_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-18T15:08:07.896693Z",
     "iopub.status.busy": "2024-10-18T15:08:07.896272Z",
     "iopub.status.idle": "2024-10-18T15:08:08.275092Z",
     "shell.execute_reply": "2024-10-18T15:08:08.273893Z",
     "shell.execute_reply.started": "2024-10-18T15:08:07.896655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling,TrainingArguments,Trainer\n",
    "\n",
    "from datasets import Dataset\n",
    "data_list = data.tolist()\n",
    "dataset = Dataset.from_dict({\"text\": data_list})\n",
    "\n",
    "# 设置最大输入长度\n",
    "\n",
    "if tokenizer.mask_token is None:\n",
    "    tokenizer.add_special_tokens({'mask_token': '[MASK]'})\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# 定义tokenize函数\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=max_length)\n",
    "\n",
    "# 对数据进行tokenization\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# 定义数据collator，适用于Causal Language Modeling\n",
    "data_collator = DataCollatorForCausalLM(tokenizer=tokenizer)\n",
    "\n",
    "# 设置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    "    fp16=True,  # 如果你的GPU支持混合精度训练\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-18T15:04:07.210940Z",
     "iopub.status.busy": "2024-10-18T15:04:07.209996Z",
     "iopub.status.idle": "2024-10-18T15:04:07.218972Z",
     "shell.execute_reply": "2024-10-18T15:04:07.218290Z",
     "shell.execute_reply.started": "2024-10-18T15:04:07.210890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-18T15:04:09.463400Z",
     "iopub.status.busy": "2024-10-18T15:04:09.462579Z",
     "iopub.status.idle": "2024-10-18T15:04:09.469049Z",
     "shell.execute_reply": "2024-10-18T15:04:09.468049Z",
     "shell.execute_reply.started": "2024-10-18T15:04:09.463355Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(tokenized_datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-18T15:08:12.358933Z",
     "iopub.status.busy": "2024-10-18T15:08:12.357958Z",
     "iopub.status.idle": "2024-10-18T15:08:19.499764Z",
     "shell.execute_reply": "2024-10-18T15:08:19.497952Z",
     "shell.execute_reply.started": "2024-10-18T15:08:12.358880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 创建Trainer对象\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets,\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3543207,
     "sourceId": 6174800,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5953458,
     "sourceId": 9728874,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
